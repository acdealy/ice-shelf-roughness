{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84de1b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import logging\n",
    "import concurrent.futures\n",
    "import time\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from pyproj import Transformer, CRS\n",
    "from shapely.geometry import Polygon, Point\n",
    "from sliderule import icesat2\n",
    "from sliderule import sliderule\n",
    "import geojson\n",
    "from scipy.interpolate import griddata\n",
    "from scipy.fft import fft, rfft, rfftfreq\n",
    "from scipy.signal import blackman,detrend\n",
    "import scipy.integrate as integrate\n",
    "from pyproj import Transformer, Geod\n",
    "import os\n",
    "import pickle\n",
    "import glob\n",
    "import scipy\n",
    "from scipy.stats import linregress\n",
    "import io\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49407b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open atl06 data\n",
    "with open('/home/acdealy/notebooks/ice-shelf-roughness/sliderule_pig_big.pickle', 'rb') as handle:\n",
    "    atl06_pig = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6faf8eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define function that takes in height/distance vectors and outputs roughness with detrended psd\n",
    "def get_roughness(h,d,k_lims):\n",
    "    diffs = np.diff(d)\n",
    "    sample_space = np.abs(np.mean(diffs))\n",
    "    n = len(d)\n",
    "    k = rfftfreq(n, sample_space)\n",
    "    yf = sample_space * rfft(h)\n",
    "    power = np.square(abs(yf))\n",
    "    psd = power*(k[1]-k[0])\n",
    "    psd = psd[(k>k_lims[0]) & (k<k_lims[1])]\n",
    "    psd_detrend = detrend(psd)\n",
    "    k = k[(k>k_lims[0]) & (k<k_lims[1])]\n",
    "    if len(psd_detrend)>1:\n",
    "        int_psd_detrend = np.max(integrate.cumulative_trapezoid(psd_detrend,k))\n",
    "        R = np.sqrt(int_psd_detrend)\n",
    "    else:\n",
    "        R=np.nan\n",
    "    return R,psd_detrend,k\n",
    "\n",
    "#calculate roughness using sliding windows\n",
    "def sliding_roughness(df,sz,slide,h_max=100,pts_per_km=10,pts_per_win=10,klims=[]):\n",
    "    d, h, E, N = df[\"d\"].values[0], df[\"h\"].values[0], df[\"E\"].values[0], df[\"N\"].values[0]\n",
    "    win_starts = np.arange(np.min(d),np.max(d),slide)\n",
    "    R, R_detrend, E_out, N_out = [], [], [], []\n",
    "    if klims == []:\n",
    "        klims = [1/sz,1/(2*scipy.stats.mode(np.diff(d))[0][0])]    \n",
    "    for i in tqdm.trange(len(win_starts)-1):\n",
    "        win_idx = [(d > win_starts[i]) & (d < win_starts[i]+sz)][0]\n",
    "        d_win, h_win, E_win, N_win = d[win_idx], h[win_idx], E[win_idx], N[win_idx]\n",
    "        pts_per_km_data = (len(d_win)/sz)*1000\n",
    "        pts_per_win_data = len(d_win)\n",
    "        if ((pts_per_km_data>pts_per_km)&(pts_per_win_data>pts_per_win)):\n",
    "            if np.sum(np.isnan(h_win))==0:\n",
    "                h_detrend = detrend(h_win)\n",
    "                roughness,_,_ = get_roughness(h_win,d_win,klims)\n",
    "                roughness_detrend,_,_ = get_roughness(h_detrend,d_win,klims)\n",
    "                R.append(roughness)\n",
    "                R_detrend.append(roughness_detrend)\n",
    "            else:\n",
    "                R.append(np.nan)\n",
    "                R_detrend.append(np.nan)\n",
    "        else:\n",
    "            R.append(np.nan)\n",
    "            R_detrend.append(np.nan)\n",
    "        E_out.append(np.nanmean(E_win))\n",
    "        N_out.append(np.nanmean(N_win))\n",
    "    return (R,R_detrend,E_out,N_out)\n",
    "\n",
    "#concatenates individual track data into one large dataframe\n",
    "def make_dataframe(atl06_data,cycle):\n",
    "    atl06_data_cycle = atl06_data[atl06_data['cycle']==cycle]\n",
    "    rgt_cycle_list = np.unique(atl06_data_cycle['rgt'])\n",
    "    strong_spot_list = [1,3,5]\n",
    "    df = pd.DataFrame(columns=[\"cycle\",\"rgt\",\"spot\",\"d\",\"h\",\"E\",\"N\",\"R\"],index=[])\n",
    "    for rgt in rgt_cycle_list:\n",
    "        for spot in strong_spot_list:\n",
    "            h = atl06_data_cycle[(atl06_data_cycle['spot']==spot)&(atl06_data_cycle['rgt']==rgt)].h_mean.values\n",
    "            lat = atl06_data_cycle[(atl06_data_cycle['spot']==spot)&(atl06_data_cycle['rgt']==rgt)]['geometry'].y.values\n",
    "            lon = atl06_data_cycle[(atl06_data_cycle['spot']==spot)&(atl06_data_cycle['rgt']==rgt)]['geometry'].x.values\n",
    "            tform = Transformer.from_crs('EPSG:4326','EPSG:3031',always_xy=True)\n",
    "            [E,N] = tform.transform(lon,lat)\n",
    "            if len(h)>100:\n",
    "                d = atl06_data_cycle[(atl06_data_cycle['spot']==spot)&(atl06_data_cycle['rgt']==rgt)]['distance'].values\n",
    "                dictionary = {\"cycle\":cycle,\"rgt\":rgt,\"spot\":spot,\"d\":d,\"h\":h,\"E\":E,\"N\":N,\"E_out\":[],\"N_out\":[],\"R\":[]}\n",
    "                dictionary = pd.DataFrame([dictionary])\n",
    "                df = pd.concat([df,dictionary],ignore_index=True)\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a0a9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameters for roughness calculation\n",
    "sz = 1000\n",
    "slide = 100\n",
    "klims = [1/1000,1/90]\n",
    "shelf = 'pig'\n",
    "num_cycles = 16\n",
    "\n",
    "#make empty dataframe\n",
    "meta_df = pd.DataFrame()\n",
    "\n",
    "#iterate through each individual cycle\n",
    "for i in range(1,num_cycles):\n",
    "    \n",
    "    #subset to just cycle n and make formated dataframe\n",
    "    atl06_pig_subset = atl06_pig[(atl06_pig['cycle']==i)]\n",
    "    meta_df_i = make_dataframe(atl06_pig_subset,i)\n",
    "    \n",
    "    #do roughness calculation for all lines in one cycle, then append to main dataframe\n",
    "    for j in range(np.shape(meta_df_i)[0]):\n",
    "        R,R_detrend,E_out,N_out = sliding_roughness(meta_df_i[j:j+1],sz,slide,100,10,5,klims)\n",
    "        meta_df_i.at[j,'R'], meta_df_i.at[j,'E_out'], meta_df_i.at[j,'N_out'], = R_detrend, E_out, N_out\n",
    "    \n",
    "    #make dataframe for each cycle\n",
    "    with open('/home/acdealy/notebooks/ice-shelf-roughness/outputs/'+shelf+'detrend'+'_df_cycle_'+str(i), 'wb') as handle:\n",
    "        pickle.dump(meta_df_i, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840402b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make empty dataframe\n",
    "meta_df = pd.DataFrame()\n",
    "\n",
    "#iterate through each cycle and concatenate each datafram\n",
    "for i in range(1,16):\n",
    "    \n",
    "    #read dataframe in format for plotting\n",
    "    meta_df_i = pd.read_pickle('/home/acdealy/notebooks/ice-shelf-roughness/outputs/'+shelf+'detrend'+'_df_cycle_'+str(i))\n",
    "    meta_df = pd.concat([meta_df,meta_df_i])\n",
    "\n",
    "#save dataframe with all cycles\n",
    "with open('/home/acdealy/notebooks/ice-shelf-roughness/outputs/'+shelf+'detrend'+'_df_cycle_all', 'wb') as handle:\n",
    "    pickle.dump(meta_df, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
